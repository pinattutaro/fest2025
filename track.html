<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>リアルタイム姿勢推定クライアント</title>
  <style>
    #video, #canvas { display: none; margin: 0 auto; }
    #console {
        width: 400px;
        height: 100px;
        position: fixed;
        top: 0px;
        left: 0px;
        background-color: rgba(0, 0, 0, 0.5);
        color: white;
        font-family: monospace;
    }
  </style>
  <script src="https://docs.opencv.org/4.x/opencv.js"></script>
  <script src="https://aframe.io/releases/1.4.0/aframe.min.js"></script>
</head>
<body>
  <div id="console"></div>
  <video id="video" autoplay playsinline width="640" height="480"></video>
  <canvas id="canvas" width="640" height="480"></canvas>

  <a-scene>
    <!-- カメラエンティティ -->
    <a-entity id="vrCamera" camera position="0 1.6 0"></a-entity>

    <!-- 簡単なオブジェクト配置 -->
    <a-box position="0 0 -3" rotation="0 45 0" color="red"></a-box>
    <a-sphere position="2 1.5 -5" radius="1.25" color="skyblue"></a-sphere>
    <a-cylinder position="-2 0.75 -4" radius="0.5" height="1.5" color="lime"></a-cylinder>
    <a-plane position="0 -0.5 -4" rotation="-90 0 0" width="10" height="10" color="#7BC8A4"></a-plane>
  </a-scene>


  <script>
    let video = document.getElementById('video');
    let canvas = document.getElementById('canvas');
    let ctx = canvas.getContext('2d');

    let orb, bf;
    let firstKeypoints, firstDescriptors;
    let firstFrame = null;

    function round2(n) {
      return Math.round((n + Number.EPSILON) * 100) / 100;
    }

    async function initCamera() {
      const stream = await navigator.mediaDevices.getUserMedia({
        video: { width: 640, height: 480, facingMode: { ideal: "environment" } }
      });
      video.srcObject = stream;
      return new Promise(res => video.onloadedmetadata = res);
    }

    function initOpenCV() {
      orb = new cv.ORB();
      bf = new cv.BFMatcher(cv.NORM_HAMMING, true);

      firstKeypoints = new cv.KeyPointVector();
      firstDescriptors = new cv.Mat();
    }

    function captureFirstFrame(gray) {
      firstFrame = gray.clone();
      orb.detectAndCompute(firstFrame, new cv.Mat(), firstKeypoints, firstDescriptors);
      console.log("初期フレームキャプチャ完了");
    }

    function processFrame(gray) {
      if (!firstFrame) {
        captureFirstFrame(gray);
        return;
      }

      let kp = new cv.KeyPointVector();
      let des = new cv.Mat();
      orb.detectAndCompute(gray, new cv.Mat(), kp, des);

      let matches = new cv.DMatchVector();
      bf.match(firstDescriptors, des, matches);

      let points1 = [], points2 = [];
      for (let i = 0; i < matches.size(); i++) {
        let m = matches.get(i);
        points1.push({ x: firstKeypoints.get(m.queryIdx).pt.x, y: firstKeypoints.get(m.queryIdx).pt.y });
        points2.push({ x: kp.get(m.trainIdx).pt.x, y: kp.get(m.trainIdx).pt.y });
      }

      if (points1.length >= 8) {
        fetch("https://05040fd5d9fc.ngrok-free.app/pose", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ points1, points2 })
        })
        .then(res => res.json())
        .then(result => {
          if(result.success === false){
            console.warn(result.message);
          } else {
            console.log("回転行列:", result.R);
            console.log("並進ベクトル:", result.t);
            document.getElementById('console').innerText = `並進ベクトル:\n${(result.t).map(e => round2(e))}\n回転行列:\n${(result.R).map(e => round2(e))}`;
            updateCamera(result.t, result.R);
          }
        })
        .catch(err => console.error(err));
      }

      kp.delete(); des.delete(); matches.delete();
    }

    let sensorRotation = { alpha:0, beta:0, gamma:0 };
    let sensorAccel = { x:0, y:0, z:0 };

    function handleOrientation(event) {
      sensorRotation.alpha = event.alpha || 0; // Z軸（yaw）
      sensorRotation.beta  = event.beta  || 0; // X軸（pitch）
      sensorRotation.gamma = event.gamma || 0; // Y軸（roll）
    }

    function handleMotion(event) {
      if (event.acceleration) {
        sensorAccel.x = event.acceleration.x || 0;
        sensorAccel.y = event.acceleration.y || 0;
        sensorAccel.z = event.acceleration.z || 0;
      }
    }

    async function enableSensors() {
      if (typeof DeviceOrientationEvent.requestPermission === 'function') {
        try {
          const state = await DeviceOrientationEvent.requestPermission();
          if (state === 'granted') {
            window.addEventListener("deviceorientation", handleOrientation);
            window.addEventListener("devicemotion", handleMotion);
          }
        } catch (err) {
          console.error("センサー許可エラー:", err);
        }
      } else {
        // iOS 13以前や非Safariブラウザ
        window.addEventListener("deviceorientation", handleOrientation);
        window.addEventListener("devicemotion", handleMotion);
      }
    }

    let lastPos = {x:0, y:0, z:0};
    let lastRot = {x:0, y:0, z:0};
    const alpha = 0.1; // 平滑化係数（0.0～1.0)
    const beta = 0.3;

    function smoothUpdate(tx, ty, tz, roll, pitch, yaw) {
      // 位置補間
      lastPos.x = lastPos.x * (1 - alpha) + tx * alpha;
      lastPos.y = lastPos.y * (1 - alpha) + ty * alpha;
      lastPos.z = lastPos.z * (1 - alpha) + (-tz) * alpha;

      // 回転補間
      lastRot.x = lastRot.x * (1 - alpha) + roll * alpha;
      lastRot.y = lastRot.y * (1 - alpha) + pitch * alpha;
      lastRot.z = lastRot.z * (1 - alpha) + yaw * alpha;

      const cam = document.getElementById("vrCamera");
      cam.setAttribute("position", `${lastPos.x} ${lastPos.y} ${lastPos.z}`);
      cam.setAttribute("rotation", `${lastRot.x} ${lastRot.y} ${lastRot.z}`);
    }

    function isJumpTooLarge(newVal, oldVal, threshold=0.5) {
      return Math.abs(newVal - oldVal) > threshold;
    }

    function updateCamera(t,R) {
      const cam = document.getElementById("vrCamera");

      // 並進ベクトル [x,y,z]
      let [tx, ty, tz] = t;
      threshold = 0.5; // 跳躍の閾値
      tx = isJumpTooLarge(tx, lastPos.x, threshold) ? lastPos.x : tx;
      ty = isJumpTooLarge(ty, lastPos.y, threshold) ? lastPos.y : ty;
      tz = isJumpTooLarge(tz, lastPos.z, threshold) ? lastPos.z : tz;
      // cam.setAttribute("position", `${tx} ${ty} ${-tz}`);

      // 回転 [roll, pitch, yaw] (deg)
      const [roll, pitch, yaw] = R;
      // cam.setAttribute("rotation", `${roll} ${pitch} ${yaw}`);

      smoothUpdate(tx, ty, tz, roll, pitch, yaw);
    }

    function mainLoop() {
      let frame = new cv.Mat(video.height, video.width, cv.CV_8UC4);
      ctx.drawImage(video, 0, 0, video.width, video.height);
      frame.data.set(ctx.getImageData(0, 0, video.width, video.height).data);

      let gray = new cv.Mat();
      cv.cvtColor(frame, gray, cv.COLOR_RGBA2GRAY);

      processFrame(gray);

      gray.delete(); frame.delete();
      requestAnimationFrame(mainLoop);
    }

    cv['onRuntimeInitialized'] = async () => {
      await initCamera();
      initOpenCV();
      mainLoop();
      await enableSensors();
    };
  </script>
</body>
</html>
